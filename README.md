# ğŸš€ SnapPix

**Official Code for DAC'25**  
**ğŸ“„ Paper Title:** *SnapPix: Efficient-Codingâ€“Inspired In-Sensor Compression for Edge Vision*

---

## ğŸ“‚ Dataset

### ğŸ”— Source  
We use [OpenMMLab Datasets](https://opendatalab.com/OpenMMLab) for all dataset used.ğŸ“¦

### âš™ï¸ Data Preprocessing  
Apply downsampling, inverse gamma correction, and grayscale conversion to dataset, here is an example for SSV2:

```bash
python preprocess_data.py ../../OpenDataLab___sthv2/raw/sthv2/sthv2/videos/ ssv2_processed/ --input_format .webm
```
See dataset/preprocessing.sh for more examples.

Process csv of SSV2:
```bash
# for finetuning dataset
python3 dataset/ssv2_list_process.py input.csv output.csv
# for pretraining dataset
python3 dataset/ssv2_list_process.py input.csv output.csv --pretrained
```

### ğŸ§¹ Generate K710 (Pretrain Dataset)  
Combining preprocessed K400 / K600 / K700 / SSV2 into one dataset:

```bash
python3 combine_pretrained.py dataset_lists/K710/train.csv dataset_lists/SSV2/train.csv \
mmdataset/k400_processed mmdataset/k600_processed mmdataset/k700_processed mmdataset/ssv2_processed combined_pretrain
```

Copy K400 / K600 / K700 to K710:
```bash
bash dataset/copy_k710.sh
```

---

## ğŸ› ï¸ Environment Setup

Refer to the [VideoMAEv2 README](https://github.com/OpenGVLab/VideoMAEv2) for detailed environment installation instructions âœ…

---

## ğŸ§ª Decorrelated Pattern Training

Train using the decorrelation strategy:

```bash
python3 VideoMAEv2/run_decorrelation_training.py
```

ğŸ” A pretrained version is available at:  
`VideoMAEv2/decorrelation_training_wd0_norm_new`

---

## ğŸ‹ï¸ï¸ Pretraining Scripts

Located in:  
`VideoMAEv2/scripts/pretrain_and_reconstruct`

Examples:  
- [`vits_pt.sh`](VideoMAEv2/scripts/pretrain_and_reconstruct/vits_pt.sh)  
- [`vitb_pt.sh`](VideoMAEv2/scripts/pretrain_and_reconstruct/vitb_pt.sh)

ğŸ“Œ Key Parameters:
- `OUTPUT_DIR`: Path to logs and checkpoints ğŸ“  
- `DATA_PATH`: CSV list of data files ğŸ“„  
- `--data_root`: Dataset root (e.g., `/local_scratch/26477563/mmdataset/`) ğŸ—‚ï¸

---

## ğŸ¯ Finetuning Scripts

Found in `scripts/finetune/`

Examples:
- [`batch_k400.sh`](VideoMAEv2/scripts/finetune/batch_k400.sh)  
- [`ssv2_ptft.sh`](VideoMAEv2/scripts/finetune/ssv2_ptft.sh)  
- [`ucf_ptft.sh`](VideoMAEv2/scripts/finetune/ucf_ptft.sh)

ğŸ”§ Key Parameters:
- `OUTPUT_DIR`: Log/checkpoint directory  
- `DATA_PATH`: Dataset list path  
- `MODEL_PATH`: Path to pretrained model  
- `--data_root`: Dataset directory

---

## ğŸ“Š Evaluation Scripts

Evaluate on different datasets using:

- ğŸ“¼ `scripts/K400_precise_val/` â€” *Kinetics-400*  
- ğŸ® `scripts/SSV2_precise_val/` â€” *Something-Something V2*  
- ğŸ“¹ `scripts/UCF_precise_val/` â€” *UCF-101*

---

## ğŸ™ Acknowledgements

A big thank you to:

- ğŸ§  **VideoMAEv2 authors** (Wang et al., CVPR 2023)  
  ğŸ”— [VideoMAEv2 GitHub](https://github.com/OpenGVLab/VideoMAEv2)

- ğŸ¥ **Action Recognition from a Single Coded Image**  
  ğŸ“„ [IEEE Paper](https://ieeexplore.ieee.org/document/9105176)

We greatly appreciate the open-source / code-sharing contributions that made SnapPix possible ğŸ’¡

